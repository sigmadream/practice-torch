{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on : LeNet5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.math import exp, maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Functions with 1-Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Input/Weight/Bias ===\n",
      "x: (1, 1)\t[[10.]]\n",
      "W: (1, 1)\t[[-1.1781762]]\n",
      "B: (1,)\t\t[0.]\n",
      "B: (1,)\t\t[0.]\n",
      "=== Outputs ===\n",
      "Y: (1, 1)\t[[-11.781761]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[10.]])\n",
    "dense = Dense(units=1, activation='linear')\n",
    "y_tf = dense(x)\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "y_manual = tf.linalg.matmul(x, W) + B\n",
    "\n",
    "print('=== Input/Weight/Bias ===')\n",
    "print(f'x: {x.shape}\\t{x.numpy()}')\n",
    "print(f'W: {W.shape}\\t{W}')\n",
    "print(f'B: {B.shape}\\t\\t{B}')\n",
    "print(f'B: {B.shape}\\t\\t{B}')\n",
    "\n",
    "print('=== Outputs ===')\n",
    "print(f'Y: {y_manual.shape}\\t{y_manual}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params Init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Input/Weight/Bias ===\n",
      "x: (1, 1)\t[[10.]]\n",
      "W: (1, 1)\t[[10.]]\n",
      "B: (1,)\t\t[20.]\n",
      "=== Outputs ===\n",
      "Y: (1, 1)\t[[120.]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[10.]])\n",
    "\n",
    "w, b = tf.constant(10.0), tf.constant(20.)\n",
    "w_init, b_init = Constant(w), Constant(b)\n",
    "\n",
    "dense = Dense(units=1, activation='linear', kernel_initializer=w_init, bias_initializer=b_init)\n",
    "\n",
    "y_tf = dense(x)\n",
    "\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "print('=== Input/Weight/Bias ===')\n",
    "print(f'x: {x.shape}\\t{x.numpy()}')\n",
    "print(f'W: {W.shape}\\t{W}')\n",
    "print(f'B: {B.shape}\\t\\t{B}')\n",
    "\n",
    "print('=== Outputs ===')\n",
    "print(f'Y: {y_tf.shape}\\t{y_tf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Functions with n-Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Input/Weight/Bias ===\n",
      "x: (1, 10)\t[[2.368828  4.0606046 0.8789623 9.845825  5.15746   5.8927035 6.9396067\n",
      "  1.4858246 2.6723826 1.4265525]]\n",
      "W: (10, 1)\t[[-0.10809839]\n",
      " [ 0.39808887]\n",
      " [-0.4797799 ]\n",
      " [-0.12114936]\n",
      " [-0.7379953 ]\n",
      " [-0.55110085]\n",
      " [-0.28600603]\n",
      " [ 0.67810994]\n",
      " [-0.5549027 ]\n",
      " [-0.16160423]]\n",
      "B: (1,)\t\t[0.]\n",
      "y_tf: (1, 1)\t[[-9.99843]]\n",
      "=== Outputs ===\n",
      "Y: (1, 1)\t[[-9.99843]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform(shape=(1, 10), minval=0, maxval=10)\n",
    "dense = Dense(units=1, activation='linear')\n",
    "y_tf = dense(x)\n",
    "W, B = dense.get_weights()\n",
    "y_manual = tf.linalg.matmul(x, W) + B\n",
    "\n",
    "print('=== Input/Weight/Bias ===')\n",
    "print(f'x: {x.shape}\\t{x.numpy()}')\n",
    "print(f'W: {W.shape}\\t{W}')\n",
    "print(f'B: {B.shape}\\t\\t{B}')\n",
    "print(f'y_tf: {y_tf.shape}\\t{y_tf}')\n",
    "\n",
    "print('=== Outputs ===')\n",
    "print(f'Y: {y_manual.shape}\\t{y_manual}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid: [[0.32064992 0.2242159  0.6038705  0.8868606  0.7401879 ]]\t[[0.32064992 0.2242159  0.6038705  0.8868606  0.7401879 ]]\n",
      "tanh: [[-0.6356181  -0.84581596  0.3982931   0.9679715   0.780616  ]]\t[[-0.63561803 -0.84581596  0.3982931   0.9679715   0.78061604]]\n",
      "relu: [[0.         0.         0.42161858 2.059067   1.0469456 ]]\t[[0.         0.         0.42161858 2.059067   1.0469456 ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal(shape=(1,5))\n",
    "\n",
    "# using Tensroflow\n",
    "sigmoid = Activation('sigmoid')\n",
    "tanh = Activation('tanh')\n",
    "relu = Activation('relu')\n",
    "\n",
    "y_sigmoid_tf = sigmoid(x)\n",
    "y_tanh_tf = tanh(x)\n",
    "y_relu_tf = relu(x)\n",
    "\n",
    "# using Manual\n",
    "\n",
    "y_sigmoid_man = 1 / (1 + exp(-x))\n",
    "y_tanh_man = (exp(x) - exp(-x))/(exp(x) + exp(-x))\n",
    "y_relu_man = maximum(x, 0)\n",
    "\n",
    "print(f'sigmoid: {y_sigmoid_tf}\\t{y_sigmoid_man}')\n",
    "print(f'tanh: {y_tanh_tf}\\t{y_tanh_man}')\n",
    "print(f'relu: {y_relu_tf}\\t{y_relu_man}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Outputs ===\n",
      "y_sigmoid: (1, 1)\t[[0.35592964]]\n",
      "y_tanh: (1, 1)\t\t[[-0.15766454]]\n",
      "y_relu: (1, 1)\t\t[[0.7153629]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal(shape=(1,5))\n",
    "\n",
    "dense_sigmoid = Dense(units=1, activation='sigmoid')\n",
    "dense_tanh = Dense(units=1, activation='tanh')\n",
    "dense_relu = Dense(units=1, activation='relu')\n",
    "\n",
    "y_sigmoid = dense_sigmoid(x)\n",
    "y_tanh = dense_tanh(x)\n",
    "y_relu = dense_relu(x)\n",
    "\n",
    "print('=== Outputs ===')\n",
    "print(f'y_sigmoid: {y_sigmoid.shape}\\t{y_sigmoid}')\n",
    "print(f'y_tanh: {y_tanh.shape}\\t\\t{y_tanh}')\n",
    "print(f'y_relu: {y_relu.shape}\\t\\t{y_relu}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu\n",
      "y_tf: [[1.231142]]\n"
     ]
    }
   ],
   "source": [
    "#activation = 'sigmoid'\n",
    "#activation = 'tanh'\n",
    "activation = 'relu'\n",
    "\n",
    "x = tf.random.uniform(shape=(1,10))\n",
    "\n",
    "dense = Dense(units=1, activation=activation)\n",
    "\n",
    "y_tf = dense(x)\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "print(f'Activation: {activation}')\n",
    "print(f'y_tf: {y_tf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (8, 10)\n",
      "Shape of W: (10, 1)\n",
      "Shape of B: (1,)\n",
      "Shape of y_tf: (8, 1)\n",
      "t_tf:\n",
      "[[0.392691  ]\n",
      " [0.6304371 ]\n",
      " [0.89559484]\n",
      " [0.7335    ]\n",
      " [0.7925204 ]\n",
      " [0.12885861]\n",
      " [0.82012224]\n",
      " [0.72107923]]\n",
      "y_manual:\n",
      "[[0.392691  ]\n",
      " [0.6304371 ]\n",
      " [0.89559484]\n",
      " [0.7335    ]\n",
      " [0.7925204 ]\n",
      " [0.12885861]\n",
      " [0.82012224]\n",
      " [0.72107923]]\n"
     ]
    }
   ],
   "source": [
    "N, n_feature = 8, 10\n",
    "x = tf.random.normal(shape=(N, n_feature))\n",
    "\n",
    "dense = Dense(units=1, activation='sigmoid')\n",
    "y_tf = dense(x)\n",
    "\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "y_manual = tf.linalg.matmul(x, W) + B\n",
    "y_manual = 1/(1 + tf.math.exp(-y_manual))\n",
    "\n",
    "print(f'Shape of x: {x.shape}')\n",
    "print(f'Shape of W: {W.shape}')\n",
    "print(f'Shape of B: {B.shape}')\n",
    "print(f'Shape of y_tf: {y_tf.shape}')\n",
    "print(f't_tf:\\n{y_tf}')\n",
    "print(f'y_manual:\\n{y_manual}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (8, 10)\n",
      "Shape of W: (10, 1)\n",
      "Shape of B: (1,)\n"
     ]
    }
   ],
   "source": [
    "N, n_feature = 8, 10\n",
    "x = tf.random.normal(shape=(N, n_feature))\n",
    "\n",
    "dense = Dense(units=1, activation='tanh')\n",
    "y = dense(x)\n",
    "\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "print(f'Shape of x: {x.shape}')\n",
    "print(f'Shape of W: {W.shape}')\n",
    "print(f'Shape of B: {B.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b90742dce02f001de07d8c2d0570961fbea14b78a10cc19a6fe9a9913083bcc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
